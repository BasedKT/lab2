{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "Methods = Enum('Methods', ['Classic', 'Momentum', 'AdaGrad', 'RMSprop', 'Adam', 'Nesterov'])\n",
    "Regularization = Enum('Regularization', ['WithoutRegularization', 'L1', 'L2', 'Elastic'])\n",
    "LearningRate = Enum('LearningRate', ['Const', 'Dichotomy'])\n",
    "LearningRateScheduling = Enum('LearningRateScheduling', ['Classic', 'Stepwise', 'Exponential'])\n",
    "\n",
    "\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, T, W, X, Y, regularization=Regularization.WithoutRegularization, l1=0.1, l2=0.1):\n",
    "        self.T = np.array([T[i % len(T)](X[i // len(T)]) for i in range(len(T) * len(X))]).reshape(len(X), len(T))\n",
    "        self.W = W\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.regularization = regularization\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.W_points = [np.copy(self.W)]\n",
    "        self.loss_values = [self.loss(self.W)]\n",
    "\n",
    "    def loss(self, W_Arg):\n",
    "        val = sum([(np.dot(self.T[i], W_Arg) - self.Y[i]) ** 2 for i in range(len(self.X))])\n",
    "        match self.regularization:\n",
    "            case Regularization.L1:\n",
    "                val += self.l1 * sum([abs(w) for w in self.W]) / len(self.W)\n",
    "            case Regularization.L2:\n",
    "                val += self.l2 * sum([w ** 2 for w in self.W]) / len(self.W)\n",
    "            case Regularization.Elastic:\n",
    "                val += (self.l1 * sum([abs(w) for w in self.W])) / len(self.W) + (\n",
    "                        self.l2 * sum([w ** 2 for w in self.W])) / len(self.W)\n",
    "        return val\n",
    "\n",
    "    def grad_by_components(self, index_components, W_Arg):\n",
    "        grad_with_batch = np.zeros(len(W_Arg))\n",
    "        for i in index_components:\n",
    "            grad_with_batch += (2 * (np.dot(self.T[i], W_Arg) - self.Y[i]) * self.T[i])\n",
    "        match self.regularization:\n",
    "            case Regularization.L1:\n",
    "                grad_with_batch += self.l1 * np.array([sign(w) for w in self.W]) / len(self.W)\n",
    "            case Regularization.L2:\n",
    "                grad_with_batch += self.l2 * 2 * self.W / len(self.W)\n",
    "            case Regularization.Elastic:\n",
    "                grad_with_batch += (self.l1 * np.array([sign(w) for w in self.W])) / len(self.W) + (\n",
    "                        self.l2 * 2 * self.W) / len(self.W)\n",
    "\n",
    "        return grad_with_batch\n",
    "\n",
    "\n",
    "def sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1, beta_2, eps_adam, is_corr_beta_1=True,\n",
    "        is_corr_beta_2=True, is_nesterov=False, decay=0.95, is_adagrad=False, without_squares=False, store_points=False):\n",
    "    i = -1\n",
    "    prev_W = lin_reg.loss(lin_reg.W)\n",
    "    V = np.zeros(len(lin_reg.W))\n",
    "    S = np.zeros(len(lin_reg.W))\n",
    "    lrs_func = lrs_handler(lrs, decay)\n",
    "\n",
    "    while True:\n",
    "        i += 1\n",
    "\n",
    "        components = [(i * batch + j) % len(lin_reg.X) for j in range(batch)]\n",
    "        cur_w = lin_reg.W\n",
    "        grad_with_batch = lin_reg.grad_by_components(components, cur_w)\n",
    "\n",
    "        alpha = lrs_func(lr(lambda a: lin_reg.loss(lin_reg.W - a * grad_with_batch)), (i * batch) // len(lin_reg.X))\n",
    "        if is_nesterov:\n",
    "            cur_w -= alpha * beta_1 * V\n",
    "            grad_with_batch = lin_reg.grad_by_components(components, cur_w)\n",
    "\n",
    "        V = (beta_1 * V) + (1 - beta_1) * grad_with_batch\n",
    "        S = (beta_2 * S) + (1 - beta_2) * (grad_with_batch ** 2) if ~is_adagrad else (S + (grad_with_batch ** 2))\n",
    "        V_norm = V / (1 - (beta_1 ** (i + 1))) if is_corr_beta_1 else V\n",
    "        S_norm = S / (1 - (beta_2 ** (i + 1))) if is_corr_beta_2 else S\n",
    "\n",
    "        if without_squares:\n",
    "            lin_reg.W = lin_reg.W - alpha * V_norm\n",
    "        else:\n",
    "            lin_reg.W = lin_reg.W - alpha * (V_norm / (((S_norm) + eps_adam) ** 0.5))\n",
    "\n",
    "        if store_points:\n",
    "            lin_reg.W_points.append(np.copy(lin_reg.W))\n",
    "        lin_reg.loss_values.append(lin_reg.loss(lin_reg.W))\n",
    "        if abs(lin_reg.loss(lin_reg.W) - prev_W) < eps or i >= max_num_of_step:\n",
    "            break\n",
    "        prev_W = lin_reg.loss(lin_reg.W)\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def sgd_handler(lin_reg, lr, method, lrs=LearningRateScheduling.Classic, batch=1, beta_1=0.9, beta_2=0.999,\n",
    "                eps_adam=10 ** -8,\n",
    "                eps=0.001, max_num_of_step=1000, store_points=False):\n",
    "    match method:\n",
    "        case Methods.Classic:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1=0, beta_2=1, eps_adam=1,\n",
    "                       is_corr_beta_1=False, is_corr_beta_2=False, without_squares=True, store_points=store_points)\n",
    "        case Methods.Momentum:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1, beta_2=1, eps_adam=1,\n",
    "                       is_corr_beta_1=False, is_corr_beta_2=False, without_squares=True, store_points=store_points)\n",
    "        case Methods.AdaGrad:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1=0, beta_2=0.5, eps_adam=eps_adam,\n",
    "                       is_corr_beta_1=False, is_corr_beta_2=False, is_adagrad=True, store_points=store_points)\n",
    "        case Methods.RMSprop:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1=0, beta_2=beta_2, eps_adam=eps_adam, is_corr_beta_1=False, store_points=store_points)\n",
    "        case Methods.Adam:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1, beta_2, eps_adam, store_points=store_points)\n",
    "        case Methods.Nesterov:\n",
    "            return sgd(lin_reg, lr, lrs, eps, batch, max_num_of_step, beta_1, beta_2=1, eps_adam=1,\n",
    "                       is_corr_beta_1=False, is_corr_beta_2=False, is_nesterov=True, without_squares=True, store_points=store_points)\n",
    "\n",
    "\n",
    "def lr_dichotomy(eps, delt):\n",
    "    return lambda lin_reg: dichotomy(lin_reg, 0, right_border_calc(lin_reg), eps, delt)\n",
    "\n",
    "\n",
    "def right_border_calc(func):\n",
    "    right_start = 0.0000001\n",
    "    zero = func(0.)\n",
    "    while zero >= func(right_start):\n",
    "        right_start *= 1.3\n",
    "\n",
    "    return right_start\n",
    "\n",
    "\n",
    "def dichotomy(func, a_1, a_2, eps, delt):\n",
    "    while abs(a_1 - a_2) >= eps:\n",
    "        new_a_1 = (a_1 + a_2) / 2 - delt\n",
    "        new_a_2 = (a_1 + a_2) / 2 + delt\n",
    "        fv1 = func(new_a_1)\n",
    "        fv2 = func(new_a_2)\n",
    "        if fv2 > fv1:\n",
    "            a_2 = new_a_2\n",
    "        elif fv2 < fv1:\n",
    "            a_1 = new_a_1\n",
    "        else:\n",
    "            a_1 = new_a_1\n",
    "            a_2 = new_a_2\n",
    "    return (a_1 + a_2) / 2\n",
    "\n",
    "\n",
    "def lrs_exp(decay):\n",
    "    return lambda lr, t: lr * (decay ** t)\n",
    "\n",
    "\n",
    "def lrs_step(decay):\n",
    "    return lambda lr, t: lr / (1 + decay * t)\n",
    "\n",
    "\n",
    "def lrs_handler(lrs, decay=0.99):\n",
    "    match lrs:\n",
    "        case LearningRateScheduling.Classic:\n",
    "            return lambda lr, t: lr\n",
    "        case LearningRateScheduling.Stepwise:\n",
    "            return lrs_step(decay)\n",
    "        case LearningRateScheduling.Exponential:\n",
    "            return lrs_exp(decay)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T16:54:41.617950Z",
     "end_time": "2023-04-15T16:54:41.633588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualise_points(linear_reg):\n",
    "    x = np.linspace(min(linear_reg.X), max(linear_reg.X), 1000)\n",
    "    y = sum(\n",
    "        [linear_reg.W[i] * (x ** (len(linear_reg.W) - 1 - i)) for i in range(len(linear_reg.W))]\n",
    "    )\n",
    "    plt.plot(x, y, '-r')\n",
    "    plt.plot(linear_reg.X, linear_reg.Y, 'og', linestyle='None')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualise_linear_sgd(lin_reg):\n",
    "    values = np.reshape(lin_reg.W_points, (2, len(lin_reg.W_points)))\n",
    "    XX = np.linspace(min(values[0]) - 30, max(values[0]) + 30, 500)\n",
    "    YY = np.linspace(min(values[1]) - 30, max(values[1]) + 30, 500)\n",
    "    X, Y = np.meshgrid(XX, YY)\n",
    "    plt.contour(X, Y, lin_reg.loss([X, Y]), 20)\n",
    "\n",
    "    plt.plot(values[0], values[1], marker='.')\n",
    "    plt.plot(values[0][0], values[0][1], 'og')\n",
    "    plt.plot(values[-1][0], values[-1][1], 'or')\n",
    "    plt.xlabel('w_1')\n",
    "    plt.ylabel('w_2')\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T16:54:41.633588Z",
     "end_time": "2023-04-15T16:54:41.649202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:82: RuntimeWarning: overflow encountered in square\n",
      "  S = (beta_2 * S) + (1 - beta_2) * (grad_with_batch ** 2) if ~is_adagrad else (S + (grad_with_batch ** 2))\n",
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:82: RuntimeWarning: invalid value encountered in multiply\n",
      "  S = (beta_2 * S) + (1 - beta_2) * (grad_with_batch ** 2) if ~is_adagrad else (S + (grad_with_batch ** 2))\n",
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:34: RuntimeWarning: overflow encountered in scalar power\n",
      "  val = sum([(np.dot(self.T[i], W_Arg) - self.Y[i]) ** 2 for i in range(len(self.X))])\n",
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:94: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  if abs(lin_reg.loss(lin_reg.W) - prev_W) < eps or i >= max_num_of_step:\n",
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:48: RuntimeWarning: overflow encountered in multiply\n",
      "  grad_with_batch += (2 * (np.dot(self.T[i], W_Arg) - self.Y[i]) * self.T[i])\n",
      "C:\\Users\\vryab\\AppData\\Local\\Temp\\ipykernel_10208\\1974077792.py:81: RuntimeWarning: invalid value encountered in multiply\n",
      "  V = (beta_1 * V) + (1 - beta_1) * grad_with_batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Classic | Regularization: WithoutRegularization | Learning Rate: Const | Learning Rate Scheduling: Classic\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6012 into shape (2,1002)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 80\u001B[0m\n\u001B[0;32m     76\u001B[0m                     visualise_linear_sgd(first_tests_val)\n\u001B[0;32m     77\u001B[0m                     test_results[info] \u001B[38;5;241m=\u001B[39m results\n\u001B[1;32m---> 80\u001B[0m \u001B[43mtests\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m test_results:\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mstr\u001B[39m(key) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m -> \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[21], line 76\u001B[0m, in \u001B[0;36mtests\u001B[1;34m()\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(info)\n\u001B[0;32m     75\u001B[0m visualise_points(first_tests_val)\n\u001B[1;32m---> 76\u001B[0m \u001B[43mvisualise_linear_sgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst_tests_val\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m test_results[info] \u001B[38;5;241m=\u001B[39m results\n",
      "Cell \u001B[1;32mIn[20], line 16\u001B[0m, in \u001B[0;36mvisualise_linear_sgd\u001B[1;34m(lin_reg)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvisualise_linear_sgd\u001B[39m(lin_reg):\n\u001B[1;32m---> 16\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlin_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW_points\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlin_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW_points\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     XX \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;28mmin\u001B[39m(values[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;28mmax\u001B[39m(values[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n\u001B[0;32m     18\u001B[0m     YY \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;28mmin\u001B[39m(values[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;28mmax\u001B[39m(values[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m500\u001B[39m)\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mreshape\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgStuff\\scoop\\apps\\python310\\current\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001B[0m, in \u001B[0;36mreshape\u001B[1;34m(a, newshape, order)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_reshape_dispatcher)\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreshape\u001B[39m(a, newshape, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    200\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    201\u001B[0m \u001B[38;5;124;03m    Gives a new shape to an array without changing its data.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;124;03m           [5, 6]])\u001B[39;00m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreshape\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgStuff\\scoop\\apps\\python310\\current\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     52\u001B[0m bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, method, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bound \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mC:\\ProgStuff\\scoop\\apps\\python310\\current\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001B[0m, in \u001B[0;36m_wrapit\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     wrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(asarray(obj), method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wrap:\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, mu\u001B[38;5;241m.\u001B[39mndarray):\n",
      "\u001B[1;31mValueError\u001B[0m: cannot reshape array of size 6012 into shape (2,1002)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "\n",
    "def calc_y(x, coeffs):\n",
    "    return sum([coeffs[i] * (x ** i) for i in range(len(coeffs))])\n",
    "\n",
    "\n",
    "def generate_data(coeffs, num_of_points, x_range_left, x_range_right, deviation):\n",
    "    X = [random.uniform(x_range_left, x_range_right) for _ in range(num_of_points)]\n",
    "    Y = [calc_y(X[i], coeffs) + random.uniform(-deviation, +deviation) for i in range(num_of_points)]\n",
    "\n",
    "    return [np.array(X), np.array(Y)]\n",
    "\n",
    "\n",
    "def gen_linear_reg(coeffs, num_of_points, x_range_left, x_range_right, deviation, calculated_lambdas):\n",
    "    T = np.array(calculated_lambdas)\n",
    "    points = generate_data(coeffs, num_of_points, x_range_left, x_range_right, deviation)\n",
    "    X, Y = points\n",
    "    W = np.zeros(len(coeffs))\n",
    "    return LinearRegression(T, W, X, Y)\n",
    "\n",
    "\n",
    "def test_universal(lin_reg, lr, method, lrs):\n",
    "    # 1 - mem, 2 - steps, 3 - time, 4 - sqrs\n",
    "    res_univ = []\n",
    "\n",
    "    start = time.time()\n",
    "    tracemalloc.start()\n",
    "    steps = sgd_handler(lin_reg, lr, method, lrs=lrs, store_points=True)\n",
    "    res_univ.append(tracemalloc.get_traced_memory())\n",
    "    tracemalloc.stop()\n",
    "    end = time.time()\n",
    "\n",
    "    res_univ.append(steps)\n",
    "    res_univ.append(end - start)\n",
    "    res_univ.append(lin_reg.loss(lin_reg.W) / len(lin_reg.X))\n",
    "\n",
    "    return res_univ\n",
    "\n",
    "\n",
    "power_lambda = lambda power: lambda x: x ** power\n",
    "\n",
    "first_tests_val = gen_linear_reg(\n",
    "    coeffs=[24., -26., -15., 25., -9., 1.],\n",
    "    num_of_points=15,\n",
    "    x_range_left=1.,\n",
    "    x_range_right=4.,\n",
    "    deviation=0.,\n",
    "    calculated_lambdas=np.array([power_lambda(5 - i) for i in range(6)])\n",
    ")\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "\n",
    "def tests():\n",
    "    for method in Methods:\n",
    "        for regularization in Regularization:\n",
    "            for lr in LearningRate:\n",
    "                for lrs in LearningRateScheduling:\n",
    "                    cur_lr = None\n",
    "                    if lr == LearningRate.Const:\n",
    "                        cur_lr = lambda x: 0.001\n",
    "                    elif lr == LearningRate.Dichotomy:\n",
    "                        cur_lr = lr_dichotomy(0.001, 0.0001)\n",
    "                    info = 'Method: {} | Regularization: {} | Learning Rate: {} | Learning Rate Scheduling: {}'\\\n",
    "                        .format(method.name, regularization.name, lr.name, lrs.name)\n",
    "\n",
    "                    first_tests_val.W = np.zeros(len(first_tests_val.W))\n",
    "                    first_tests_val.W_points = [np.copy(first_tests_val.W)]\n",
    "                    first_tests_val.loss_values = [first_tests_val.loss(first_tests_val.W)]\n",
    "                    results = test_universal(first_tests_val, cur_lr, method, lrs)\n",
    "\n",
    "                    print(info)\n",
    "                    visualise_points(first_tests_val)\n",
    "                    test_results[info] = results\n",
    "\n",
    "\n",
    "tests()\n",
    "\n",
    "for key in test_results:\n",
    "    print(str(key) + \" -> \")\n",
    "    print('\\n'.join(str(val) for val in test_results[key]))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T01:33:50.150579Z",
     "end_time": "2023-04-15T01:33:53.318099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# n = 3\n",
    "#\n",
    "# current_t = np.array(np.array([power_lambda(n - 1 - i) for i in range(n)]))\n",
    "# current_w = np.zeros(n)\n",
    "# current_x = np.array([1., 2., 9., -2., -10.])\n",
    "# current_y = np.array([1., 2., 9., -2., 5])\n",
    "#\n",
    "# for method in Methods:\n",
    "#     for regularization in Regularization:\n",
    "#         for lr in LearningRate:\n",
    "#             linear_reg_const = LinearRegression(\n",
    "#                 current_t, current_w, current_x, current_y, regularization\n",
    "#             )\n",
    "#             print(str(method) + \" \" + str(regularization) + \" \" + str(lr))\n",
    "#             if lr == LearningRate.Const:\n",
    "#                 sgd_handler(linear_reg_const, lambda x: 0.01, method)\n",
    "#             elif lr == LearningRate.Dichotomy:\n",
    "#                 sgd_handler(linear_reg_const, lr_dichotomy(0.001, 0.0001), method)\n",
    "#             visualise_points(linear_reg_const)\n",
    "#             visualise_loss(np.array(linear_reg_const.loss_values))\n",
    "#             current_w = np.zeros(n)\n",
    "#             print(\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T01:33:53.292101Z",
     "end_time": "2023-04-15T01:33:53.319099Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
